{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPGFx-LsvLMY",
        "outputId": "1c9edc5f-e642-488c-e1c8-393cebc37c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pyautogen[retrievechat]~=0.2.0b5 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.36)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.6)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.18)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (5.6.3)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (2.1.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (1.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (2.3.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (7.34.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (3.17.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from pyautogen[retrievechat]~=0.2.0b5) (2.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.6)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro==1.8.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.8.2)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.18)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.104.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.24.0.post1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.2)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.3)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.2)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (28.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.19.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->pyautogen[retrievechat]~=0.2.0b5) (4.8.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (4.35.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (0.16.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (0.1.99)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->pyautogen[retrievechat]~=0.2.0b5) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->pyautogen[retrievechat]~=0.2.0b5) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->pyautogen[retrievechat]~=0.2.0b5) (0.2.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (2.1.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (0.4.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (9.4.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers->pyautogen[retrievechat]~=0.2.0b5) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai \"pyautogen[retrievechat]~=0.2.0b5\" tiktoken cohere kaleido python-multipart chromadb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOkryV798spY",
        "outputId": "5c4422af-e7a2-408b-9323-3f287e445f8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.66 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "\n",
        "config_list = [\n",
        "    {\n",
        "        \"model\": \"gpt-3.5-turbo\",\n",
        "        \"api_key\": \"api-key\"\n",
        "    }\n",
        "]\n",
        "llm_config = {\n",
        "    \"seed\": 42,\n",
        "    \"config_list\": config_list,\n",
        "    \"temperature\": 0\n",
        "}"
      ],
      "metadata": {
        "id": "rUc0FaHQwQD8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb.utils import embedding_functions\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key = \"api-key\",\n",
        "    model_name = \"text-embedding-ada-002\"\n",
        ")\n",
        "\n",
        "r_spliter = RecursiveCharacterTextSplitter(separators = [\"\\n\", \"\\r\", \"\\t\"])"
      ],
      "metadata": {
        "id": "PmyFRd-08Uhf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import autogen\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "\n",
        "assistant = autogen.AssistantAgent(\n",
        "    name = \"assistant\",\n",
        "    llm_config = llm_config,\n",
        "    system_message = \"You are a helpful assistant\",\n",
        "    is_termination_msg = lambda x: isinstance(x, dict) and \"TERMINATION\" == str(x.get(\"content\", \"\"))[-9:].upper(),\n",
        ")\n",
        "\n",
        "retrieceuserproxy = RetrieveUserProxyAgent(\n",
        "    name = \"retreive_userproxy\",\n",
        "    system_message = \"Assistant who has extra content retrieval power for solving difficult problems.\",\n",
        "    is_termination_msg = lambda x: isinstance(x, dict) and \"TERMINATION\" == str(x.get(\"content\", \"\"))[-9:].upper(),\n",
        "    human_input_mode = \"NEVER\",\n",
        "    max_consecutive_auto_reply = 3,\n",
        "    retrieve_config = {\n",
        "        \"task\": \"qa\",\n",
        "        \"docs_path\": \"/content/cs224u-contextualreps-2023-handout.pdf\",\n",
        "        \"custom_text_split_function\": r_spliter.split_text,\n",
        "        \"embedding_function\": openai_ef,\n",
        "        \"chunk_token_size\": 1000,\n",
        "        \"model\": \"gpt-3.5-turbo-0613\",\n",
        "        # \"collection_name\": \"groupchat\",\n",
        "        \"get_or_create\": True,\n",
        "\n",
        "    },\n",
        "    code_execution_config = False\n",
        ")"
      ],
      "metadata": {
        "id": "bjOQ0oS6x84-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant.reset()\n",
        "retrieceuserproxy.initiate_chat(assistant, problem = \"What is the role of postional encoding?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTm2KmW914Ap",
        "outputId": "70723091-c668-4c0b-e0c0-981290eba4b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to create collection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogen.retrieve_utils:Found 23 chunks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc_ids:  [['doc_0', 'doc_3', 'doc_15', 'doc_18', 'doc_5', 'doc_2', 'doc_17', 'doc_11', 'doc_1', 'doc_16', 'doc_6', 'doc_21', 'doc_10', 'doc_14', 'doc_4', 'doc_8', 'doc_20', 'doc_19', 'doc_22', 'doc_9']]\n",
            "Adding doc_id doc_0 to context.\n",
            "retreive_userproxy (to assistant):\n",
            "\n",
            "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "You must give as short an answer as possible.\n",
            "\n",
            "User's question is: What is the role of postional encoding?\n",
            "\n",
            "Context is: Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Contextual word representations\n",
            "Christopher Potts\n",
            "Stanford Linguistics\n",
            "CS224u: Natural language understanding\n",
            "1 / 81\n",
            "Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Guiding ideas\n",
            "2 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Static vector representations of words\n",
            "1.Feature-based (sparse): Classical lexical representations\n",
            "2.Count-based methods (sparse): PMI, TF-IDF, etc.\n",
            "3.Classical dimensionality reduction (dense): PCA, SVD,\n",
            "LDA, etc.\n",
            "4.Learned dimensionality reduction (dense): autoencoders,\n",
            "word2vec, GloVe, etc.\n",
            "Hands-on review:\n",
            "https://web.stanford.edu/class/cs224u/background.html\n",
            "3 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Word representations and context\n",
            "1.a.The vase broke.\n",
            "b.Dawn broke.\n",
            "c.The news broke.\n",
            "d.Sandy broke the world record.\n",
            "e.Sandy broke the law.\n",
            "f.The burglar broke into the house.\n",
            "g.The newscaster broke into the movie broadcast.\n",
            "h.We broke even.\n",
            "2.a.ﬂat tire/beer/note/surface\n",
            "b.throw a party/ﬁght/ball/ﬁt\n",
            "3.a.A crane caught a ﬁsh.\n",
            "b.A crane picked up the steel beam.\n",
            "c.I saw a crane.\n",
            "4.a.Are there typos? I didn’t see any.\n",
            "b.Are there bookstores downtown? I didn’t see any.\n",
            "4 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "A brief history of contextual representation\n",
            "1.November 2015 :Dai and Le (2015 ) showed the value of\n",
            "LM-style pretraining for downstream tasks.\n",
            "2.August 2017 :McCann et al. (2017 ) (CoVe) pretrained\n",
            "bi-LSTMs for machine translation and showed that this\n",
            "was a useful start-state for downstream tasks.\n",
            "3.February 2018 :Peters et al. (2018 ) (ELMo) ﬁrst showed\n",
            "how very large-scale pretraining of bidirectional LSTMs\n",
            "can lead to rich multipurpose representations.\n",
            "4.June 2018 :Radford et al. (2018 ) introduced GPT.\n",
            "5.October 2018 :Devlin et al. (2019 ) introduced BERT.\n",
            "5 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Model structure and linguistic structure\n",
            "TheRockrulesx47x30x34h1hrTherockrulesx47x30x34h1h2h3\n",
            "TheRockrulesx47x30x34x+\n",
            "TheRockrulesx47x30x34h1h2h3•••attention\n",
            "6 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Attention\n",
            "classiﬁer y=softmax (˜hW +b)\n",
            "attention combo˜h= tanh([ p;hC]Wp)\n",
            "context p=mean ([g1h1, g2h2, g3h3])\n",
            "attention weights g=softmax (˜g)\n",
            "scores ˜g=\n",
            "h⊤\n",
            "Ch1h⊤\n",
            "Ch2h⊤\n",
            "Ch3\n",
            "really good not so x36 x45 x39 x1 1 h1 h2 h3 hC \n",
            "7 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Subword modeling in ELMo\n",
            "r u l e sFilters of different length, obtained\n",
            "via dense layers processing the\n",
            "input character embeddings and\n",
            "combined via max-pooling:\n",
            "4 2 6 1\n",
            "1 7 8 2\n",
            "1 3 9 3\n",
            "4 7 9 3Max-pooling layers concatenated\n",
            "to form the word representation\n",
            "8 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Guiding idea: Word pieces\n",
            "iQF2MBxBM;J\u001c`+? ke- kyky(R),7`QKi`\u001cMb7Q`K2`bBKTQ`i\"2`ihQF2MBx2`(k),iQF2MBx2`4\"2`ihQF2MBx2`X7`QKnT`2i`\u001cBM2/U^#2`i@#\u001cb2@+\u001cb2/^V(j),iQF2MBx2`XiQF2MBx2U]h?Bb BbM^i iQQ bm`T`BbBM;X]V(j),(^h?Bb^- ^BbM^- ]^]- ^i^- ^iQQ^- ^bm`T`BbBM;^- ^X^)(9),iQF2MBx2`XiQF2MBx2U]1M+Q/2 K25]V(9),(^1M^- ^OO+Q/2^- ^K2^- ^5^)(8),iQF2MBx2`XiQF2MBx2U]aMm77H2mT\u001c;mb\\]V(8),(^a^- ^OOMm^- ^OO77H2^- ^OOmT^- ^OO\u001c;m^- ^OOb^- ^\\^)(e),iQF2MBx2`XpQ+\u001c#nbBx2(e),k3NNe\n",
            "R\n",
            "9 / 81Sennrich et al. 2016 ,\n",
            "https://github.com/google/sentencepieceGuiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Guiding idea: Positional encoding\n",
            "The 1 Rock 2 rules 3x47 p1 x30 p2 x34 p3ainput binput cinput\n",
            "+ + +\n",
            "10 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Guiding idea: Massive scale pretraining\n",
            "11 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to retreive_userproxy):\n",
            "\n",
            "The role of positional encoding is to provide information about the position of words in a sequence to the transformer model.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "retreive_userproxy (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to retreive_userproxy):\n",
            "\n",
            "UPDATE CONTEXT\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Updating context and resetting conversation.\n",
            "Adding doc_id doc_3 to context.\n",
            "Adding doc_id doc_15 to context.\n",
            "retreive_userproxy (to assistant):\n",
            "\n",
            "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "You must give as short an answer as possible.\n",
            "\n",
            "User's question is: What is the role of postional encoding?\n",
            "\n",
            "Context is: aK\n",
            "4,1=wK\n",
            "−2aK\n",
            "4,2=wK\n",
            "−2aK\n",
            "4,3=wK\n",
            "−1aK\n",
            "4,4=wK\n",
            "0aK\n",
            "4,5=wK\n",
            "1aK\n",
            "4,6=wK\n",
            "2aK\n",
            "4,7=wK\n",
            "2\n",
            "aK\n",
            "3,1=wK\n",
            "−2aK\n",
            "3,2=wK\n",
            "−1aK\n",
            "3,3=wK\n",
            "0\n",
            "Same logic for the representations aV\n",
            "ij.\n",
            "26 / 81Shaw et al. 2018Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Relative positional encoding: Full deﬁnition\n",
            "With learned attention parameters:\n",
            "attn i=n∑\n",
            "j=1gij\n",
            "xjWV+aV\n",
            "ij\n",
            "gij=softmax \n",
            "(xiWQ)⊤(xjWK+aK\n",
            "ij)\n",
            "p\n",
            "dk!\n",
            "Limitations\n",
            "1.Setofposition needs tobedecided ahead oftime.\n",
            "2.May hindergeneralization tonew positions, even for\n",
            "familiarphenom ena.\n",
            "The Rock\n",
            "wK\n",
            "0wK\n",
            "1wK\n",
            "−1\n",
            "27 / 81Shaw et al. 2018Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT\n",
            "28 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Autoregressive loss function\n",
            "For vocabulary V, sequence x= [x1, . . . , xT], and word-level\n",
            "embedding e:\n",
            "max\n",
            "nT∑\n",
            "t=1logexp\u0000\n",
            "e(xt)⊤hn(x1:t−1)\u0001\n",
            "∑\n",
            "x′∈Vexp\u0000\n",
            "e(x′)⊤hn(x1:t−1)\u0001\n",
            "for model parameters hn.\n",
            "29 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Conditional language modeling\n",
            "x= [〈s〉,The,Rock ,rules ,〈/s〉]\n",
            "t1 t2 t3 t4〈s〉 The Rock rulesx0 x47 x30 x34h1 h2 h3 h4The Rock rules 〈/s〉t2 t3 t4 t5\n",
            "Rock .exp\n",
            "x30⊤ h2\n",
            "30 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT\n",
            "〈s〉 0 The 1 Rock 2 rules 3x47 p0 x47 p1 x30 p2 x34 p3〈s〉inain bincin\n",
            "+ + + +〈s〉outaout boutcout\n",
            "T ransformer blocksThe Rock rules 〈/s〉\n",
            "31 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Attention masking\n",
            "ainput binput cinputaattn battn cattn\n",
            "32 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: T raining with teacher forcing\n",
            "[1,0,0,0,0,0,0,0] [0,0,1,0,0,0,0,0] [0,0,0,0,1,0,0,0] [0,0,0,0,0,1,0,0]dk× |V| dk× |V| dk× |V| dk× |V|[BOS] The Rock rulesdk× |V| dk× |V| dk× |V| dk× |V|[0,0,\n",
            "The\n",
            "1,0,0,0,0,0] [0,0,0,0,\n",
            "Rock\n",
            "1,0,0,0] [0,0,0,0,0,\n",
            "rules\n",
            "1,0,0] [0,\n",
            "[EOS]\n",
            "1,0,0,0,0,0,0]\n",
            "[1,7,9,2,3,4,8,1] [3,2,1,1,6,5,4,4] [1,2,4,6,2,1,0,7] [1,9,2,1,2,3,3,6]\n",
            "33 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "Generation\n",
            "[1,0,0,0,0,0,0,0] [0,0,1,0,0,0,0,0]dk× |V| dk× |V|[BOS] Thedk× |V| dk× |V|[0,0,\n",
            "The\n",
            "1,0,0,0,0,0] [0,0,0,0,\n",
            "Rock\n",
            "1,0,0,0]\n",
            "[0,0,0,0,1,0,0,0]dk× |V|Rockdk× |V|[1,2,4,6,2,1,0,\n",
            "rolls\n",
            "7]\n",
            "[0,0,0,0,0,0,0,1]dk× |V|rollsdk× |V|[1,1,1,\n",
            "along\n",
            "9,1,3,1]\n",
            "34 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Fine-tuning\n",
            "〈s〉 0 The 1 Rock 2 rules 3x47 p0 x47 p1 x30 p2 x34 p3〈s〉inain bincin\n",
            "+ + + +〈s〉outaout boutcout\n",
            "T ransformer blocks\n",
            "35 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Fine-tuning\n",
            "〈s〉 0 The 1 Rock 2 rules 3x47 p0 x47 p1 x30 p2 x34 p3〈s〉inain bincin\n",
            "+ + + +〈s〉outaout boutcout\n",
            "T ransformer blocks\n",
            "35 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Fine-tuning\n",
            "〈s〉 0 The 1 Rock 2 rules 3x47 p0 x47 p1 x30 p2 x34 p3〈s〉inain bincin\n",
            "+ + + +〈s〉outaout boutcout\n",
            "T ransformer blocks\n",
            "35 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Fine-tuning\n",
            "〈s〉 0 The 1 Rock 2 rules 3x47 p0 x47 p1 x30 p2 x34 p3〈s〉inain bincin\n",
            "+ + + +〈s〉outaout boutcout\n",
            "T ransformer blocks\n",
            "35 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Scaling up from OpenAI\n",
            "Layers dk dffParameters\n",
            "GPT ( Radford et al. 2018 ) 12 768 3,072 117M\n",
            "GPT-2 ( Radford et al. 2019 ) 48 1,600 1,600 1,542M\n",
            "GPT-3 ( Brown et al. 2020 ) 96 12,288 ? 175,000M\n",
            "The GPT-3 paper also reports on models ranging in size from 125M to\n",
            "13B (T able 2.1).\n",
            "36 / 81Guiding ideas T ransformer Pos enc GPT BERT RoBERT a ELECTRA seq2seq Distillation Wrap-up\n",
            "GPT: Scaling up truly open models\n",
            "Layers dk dffParameters\n",
            "GPT-Neo ( Eleuther ) 24 2,048 2,048 2,700M\n",
            "GPT-J ( Eleuther ) 28 4,096 16,384 6,000M\n",
            "1All our code and models are publicly available athttp://nlp.stanford.edu/projects/nmt.B C D <eos> X Y ZXYZ<eos>\n",
            "AFigure 1:Neural machine translation–as t a c k -ing recurrent architecture for translating a sourcesequenceABCDinto a target sequenceXYZ.H e r e ,<eos>marks the end of a sentence.is often a large neural network that is trained in anend-to-end fashion and has the ability to general-ize well to very long word sequences. This meansthe model does not have to explicitly store giganticphrase tables and language models as in the caseof standard MT; hence, NMT has a small memoryfootprint. Lastly, implementing NMT decoders iseasy unlike the highly intricate decoders in stan-dard MT (Koehn et al., 2003).In parallel, the concept of “attention” has gainedpopularity recently in training neural networks, al-lowing models to learn alignments between dif-ferent modalities, e.g., between image objectsand agent actions in the dynamic control problem(Mnih et al., 2014), between speech frames andtext in the speech recognition task (Chorowski etal., 2014), or between visual features of a pictureand its text description in the image caption gen-eration task (Xu et al., 2015). In the context ofNMT, Bahdanau et al. (2015) has successfully ap-plied such attentional mechanism to jointly trans-late and align words. To the best of our knowl-edge, there has not been any other work exploringthe use of attention-based architectures for NMT.In this work, we design, with simplicity and ef-fectiveness in mind, two novel types of attention-1412\n",
            "˜htAttention Layer\n",
            "B C D <eos> X Y ZXYZ<eos>\n",
            "AFigure 4:Input-feeding approach–A t t e n t i o n a lvectors˜htare fed as inputs to the next time steps toinform the model about past alignment decisions.3.3 Input-feeding ApproachIn our proposed global and local approaches,the attentional decisions are made independently,which is suboptimal. Whereas, in standard MT,acoverageset is often maintained during thetranslation process to keep track of which sourcewords have been translated. Likewise, in atten-tional NMTs, alignment decisions should be madejointly taking into account past alignment infor-mation. To address that, we propose aninput-feedingapproach in which attentional vectors˜htare concatenated with inputs at the next time stepsas illustrated in Figure 4.11The effects of hav-ing such connections are two-fold: (a) we hopeto make the model fully aware of previous align-ment choices and (b) we create a very deep net-work spanning both horizontally and vertically.Comparison to other work–B a h d a n a ue ta l .(2015) use context vectors, similar to ourct,i nbuilding subsequent hidden states, which can alsoachieve the “coverage” effect. However, there hasnot been any analysis of whether such connectionsare useful as done in this work. Also, our approachis more general; as illustrated in Figure 4, it can beapplied to general stacking recurrent architectures,including non-attentional models.Xu et al. (2015) propose adoubly attentionalapproach with an additional constraint added tothe training objective to make sure the model paysequal attention to all parts of the image during thecaption generation process. Such a constraint can\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to retreive_userproxy):\n",
            "\n",
            "Positional encoding is used in transformer models to provide information about the position of each token in the input sequence. It helps the model differentiate between tokens based on their position, which is important for tasks like language translation or text generation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "retreive_userproxy (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to retreive_userproxy):\n",
            "\n",
            "UPDATE CONTEXT\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcMZ-iQZ2atv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}